# GNCIPL Internship Projects

This repository contains the projects completed during my internship at **GLOBAL NEXT CONSULTING INDIA PRIVATE LIMITED (GNCIPL).**

üè¢ **Company:** GLOBAL NEXT CONSULTING INDIA PVT. LTD.  
üßë‚Äçüíª **Intern:** Aravind B  
üìÖ **Internship Period:** [Insert Duration ‚Äì 22, July 2025]  
üåê **Website:** www.gncipl.com

---

##  Dataset Links

- **Credit Card Fraud Detection Dataset**: [Kaggle ‚Äì Credit Card Fraud Detection (ULB)](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)  
- **Air Quality Dataset**: [Kaggle ‚Äì Air Quality Data Set](https://www.kaggle.com/datasets/fedesoriano/air-quality-data-set)

---

## üìÅ Projects Included

### 1. Credit Card Fraud Detection (week 1)
**Domain:** Finance / Cybersecurity  
**Tools Used:** Python, Pandas, Scikit-learn, Matplotlib, PCA, SMOTE  
**Dataset:** Kaggle ‚Äì Credit Card Fraud Detection  
**Dataset Link:** [Credit Card Fraud Detection (ULB)](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

**Description:**  
Implemented a machine learning pipeline to detect fraudulent transactions in a highly imbalanced dataset using classification models and dimensionality reduction.

**Highlights:**  
- Applied PCA to reduce dimensionality  
- Handled class imbalance with SMOTE  
- Evaluated models using precision, recall, and confusion matrix  

---

### 2. COVID-19 Trend Prediction (week 2)
**Domain:** Medical Science / Time-Series Analysis  
**Tools Used:** Python, Pandas, ARIMA, Prophet, Matplotlib  
**Dataset:** COVID-19 Time Series Data (Global) ‚Äì Kaggle  

**Description:**  
Analyzed global and country-wise COVID-19 case trends over time and implemented time-series forecasting models to predict future cases.

**Highlights:**  
- Data cleaning and transformation from daily CSV files  
- Forecasted daily counts using ARIMA and/or Prophet models  
- Visualized trend lines, growth rate, and prediction intervals  

---

### 3. Customer Segmentation for a Retail Store (week 3)
**Domain:** Retail Analytics / Unsupervised Machine Learning  
**Tools Used:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, K-Means, PCA  
**Dataset:** Mall Customers Dataset (Kaggle)  

**Description:**  
Used K-Means clustering to segment retail customers based on demographics and spending behavior for targeted marketing.

**Highlights:**  
- Cleaned and scaled customer data  
- Determined optimal clusters using Elbow Method & Silhouette Score  
- Applied K-Means, visualized with PCA (2D & 3D plots)  
- Derived actionable marketing insights from distinct customer groups  

---

### 4. Air Quality Clustering & Analysis (week 4)  
**Domain:** Environmental Data Science / Unsupervised Machine Learning  
**Tools Used:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, Plotly, PCA, t-SNE, K-Means, Hierarchical Clustering  
**Dataset:** Air Quality Data (Kaggle ‚Äì Air Quality Dataset)  
**Dataset Link:** [Air Quality Data Set (Fedesoriano)](https://www.kaggle.com/datasets/fedesoriano/air-quality-data-set)

**Description:**  
Implemented unsupervised learning techniques to cluster air quality data and identify pollution patterns across regions. Focused on dimensionality reduction (PCA & t-SNE), clustering (K-Means & Hierarchical), and cluster evaluation (Silhouette Score & Davies‚ÄìBouldin Index).

**Highlights:**  
- Preprocessed and scaled pollution indicators (PM‚ÇÇ.‚ÇÖ, PM‚ÇÅ‚ÇÄ, NO‚ÇÇ, CO, SO‚ÇÇ, O‚ÇÉ, etc.)  
- Determined optimal clusters using **Elbow Method**  
- Compared **K-Means vs Hierarchical Clustering** performance  
- Visualized clusters using PCA, t-SNE, and interactive Plotly graphs  
- Summarized clusters into interpretable groups:  
  - **Cluster 0:** High PM zones (industrial/traffic)  
  - **Cluster 1:** High NO‚Çì/NO‚ÇÇ zones (traffic-dense areas)  
  - **Cluster 2:** Cleaner zones (lower pollutant levels)  

---

### 5. Language Proficiency Estimator (week 5)  
**Domain:** Natural Language Processing / Education Technology  
**Tools Used:** Python, Hugging Face Transformers, Scikit-learn, Pandas, Matplotlib  
**Dataset:** Custom dataset of text samples labeled with proficiency levels (Beginner, Intermediate, Advanced)  

**Description:**  
Designed a model to estimate the language proficiency of users based on written text. The system analyzed grammar usage, vocabulary richness, and sentence structure to predict proficiency levels.

**Highlights:**  
- Preprocessed and tokenized user text samples  
- Implemented TF-IDF baseline + transformer-based models  
- Extracted linguistic features (e.g., sentence length, vocabulary diversity)  
- Classified users into **Beginner / Intermediate / Advanced**  
- Built evaluation pipeline with accuracy, recall, and F‚ÇÅ metrics  

---
